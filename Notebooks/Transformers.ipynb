{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><center>IST 597 Foundations of Deep Learning</center></h1>\n",
        "\n",
        "---\n",
        "\n",
        "<h2><center>Transformers</center><h2>\n",
        "<h3><center>Neisarg Dave</center><h3>"
      ],
      "metadata": {
        "id": "efBDLfFzKtC0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "+ https://jalammar.github.io/illustrated-transformer/\n",
        "+ https://github.com/jessevig/bertviz\n",
        "\n",
        "Torch API:\n",
        "+ [Tranformer Encoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html?highlight=transformerencoder#torch.nn.TransformerEncoder)\n",
        "+ [Transformer Encoder Layer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html?highlight=transformerencoder#torch.nn.TransformerEncoderLayer)\n",
        "+ [Transformer Decoder](https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoder.html?highlight=transformer+decoder#torch.nn.TransformerDecoder)\n",
        "+ [Transformer Decoder Layer](https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html?highlight=transformer+decoder+layer#torch.nn.TransformerDecoderLayer)\n",
        "+ [Tranformer](https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html?highlight=transformer#torch.nn.Transformer)\n",
        "+ [Multihead Attention](https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html)"
      ],
      "metadata": {
        "id": "erDplBxGK0-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math"
      ],
      "metadata": {
        "id": "HSlqKwnDKsmk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model, dtype = torch.float)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype = torch.float) * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        print(x.size(1))\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return x"
      ],
      "metadata": {
        "id": "UQE0MTzrMPvO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "1V0ltBm_KQvH"
      },
      "outputs": [],
      "source": [
        "class TransformerLanguageModel(nn.Module):\n",
        "    def __init__(self, in_dim, state_dim, vocab_size, num_layers, num_heads):\n",
        "        super(TransformerLanguageModel, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.in_dim = in_dim\n",
        "        self.state_dim = state_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.n_heads = num_heads\n",
        "        print(\"layers :\", self.num_layers, \"  num_heads : \", self.n_heads)\n",
        "        self.embedding = torch.nn.Embedding(self.vocab_size, in_dim, padding_idx=0)\n",
        "        self.pos_embedding = PositionalEncoding(in_dim, dropout=0.1, max_len = 30)\n",
        "        self.transformer = torch.nn.Transformer(d_model=in_dim, nhead=self.n_heads, num_encoder_layers=self.num_layers, \n",
        "                                num_decoder_layers=self.num_layers, dim_feedforward=state_dim, dropout=0, batch_first = True)\n",
        "        self.transformer.encoder.enable_nested_tensor = False\n",
        "        self.symbol_classifier = nn.Sequential(nn.Linear(in_dim, self.vocab_size))\n",
        "                                        \n",
        "\n",
        "    def get_tgt_mask(self, size, device):\n",
        "        mask = torch.tril(torch.ones([size, size], device = device) == 1) # Lower triangular matrix\n",
        "        mask = mask.float()\n",
        "        mask = mask.masked_fill(mask == 0, float('-inf')) \n",
        "        mask = mask.masked_fill(mask == 1, float(0.0))\n",
        "            \n",
        "        # EX for size=5:\n",
        "        # [[0., -inf, -inf, -inf, -inf],\n",
        "        #  [0.,   0., -inf, -inf, -inf],\n",
        "        #  [0.,   0.,   0., -inf, -inf],\n",
        "        #  [0.,   0.,   0.,   0., -inf],\n",
        "        #  [0.,   0.,   0.,   0.,   0.]]\n",
        "        return mask\n",
        "\n",
        "    def forward(self, exp1, exp2, len_1, len_2):\n",
        "        inp1 = self.embedding(exp1)\n",
        "        inp2 = self.embedding(exp2)\n",
        "\n",
        "        inp1 = self.pos_embedding(inp1.transpose(0,1)).transpose(0,1)\n",
        "        inp2 = self.pos_embedding(inp2.transpose(0,1)).transpose(0,1)\n",
        "\n",
        "        src_key_mask = torch.arange(inp1.shape[1]).cuda()\n",
        "        src_key_mask = src_key_mask[None] <= (len_1-1)[:, None]\n",
        "\n",
        "        tgt_key_mask = torch.arange(inp2.shape[1]).cuda()\n",
        "        tgt_key_mask = tgt_key_mask[None] <= (len_2-1)[:, None]\n",
        "\n",
        "        memory_key_mask = src_key_mask\n",
        "        tgt_mask = self.get_tgt_mask(inp2.shape[1], inp2.device)\n",
        "\n",
        "\n",
        "        out = self.transformer(inp1, inp2, src_key_padding_mask = ~src_key_mask, tgt_key_padding_mask = ~tgt_key_mask, memory_key_padding_mask = ~memory_key_mask, tgt_mask = tgt_mask)\n",
        "                                        \n",
        "        out = self.symbol_classifier(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Positional Encoding"
      ],
      "metadata": {
        "id": "syIrwQNdM4mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pe_layer = PositionalEncoding(d_model=4, max_len=16)\n",
        "pe = pe_layer(torch.zeros(1, 16, 4))\n",
        "print(pe.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnSO8pf6NRmB",
        "outputId": "6b9e0252-5ae7-4194-97c6-ab4e90ee9670"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n",
            "torch.Size([1, 16, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pe)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGhApQW0SJzH",
        "outputId": "6e5cad1b-f51d-4ae4-a635-415645d7e550"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
            "         [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
            "         [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
            "         [ 0.1411, -0.9900,  0.0300,  0.9996],\n",
            "         [-0.7568, -0.6536,  0.0400,  0.9992],\n",
            "         [-0.9589,  0.2837,  0.0500,  0.9988],\n",
            "         [-0.2794,  0.9602,  0.0600,  0.9982],\n",
            "         [ 0.6570,  0.7539,  0.0699,  0.9976],\n",
            "         [ 0.9894, -0.1455,  0.0799,  0.9968],\n",
            "         [ 0.4121, -0.9111,  0.0899,  0.9960],\n",
            "         [-0.5440, -0.8391,  0.0998,  0.9950],\n",
            "         [-1.0000,  0.0044,  0.1098,  0.9940],\n",
            "         [-0.5366,  0.8439,  0.1197,  0.9928],\n",
            "         [ 0.4202,  0.9074,  0.1296,  0.9916],\n",
            "         [ 0.9906,  0.1367,  0.1395,  0.9902],\n",
            "         [ 0.6503, -0.7597,  0.1494,  0.9888]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JRgOVX4pY6NU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}